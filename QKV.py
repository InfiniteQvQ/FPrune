import torch
from transformers import AutoModelForCausalLM, LlamaTokenizer

# **åŠ è½½ LLaMA 7B æ¨¡å‹**
cache_dir = "/root/autodl-tmp/llm_weights"
model = AutoModelForCausalLM.from_pretrained(
    "pinkmanlove/llama-7b-hf",
    cache_dir=cache_dir,
    device_map="auto",
    torch_dtype=torch.float16
)
tokenizer_name = "HuggingFaceM4/llama-7b-tokenizer"
tokenizer = LlamaTokenizer.from_pretrained(tokenizer_name)

# **å­˜å‚¨æ³¨æ„åŠ›åˆ†æ•°**
attn_scores = {}

def get_attention_scores_hook(layer_id):
    def hook(module, input, output):
        if isinstance(output, tuple) and len(output) > 1:
            attn_weights = output[1]  # å– attn_probs
            if attn_weights is not None:
                print(f"Layer {layer_id} Attention Shape:", attn_weights.shape)  # ğŸ” Debug Shape
                mean_score = attn_weights.mean(dim=[0, 1, 2])  # å…ˆå¯¹ batch, head, seq å–å‡å€¼
                if mean_score.numel() > 1:  # å¦‚æœä»ç„¶æ˜¯å¼ é‡ï¼Œå–å‡å€¼
                    mean_score = mean_score.mean()
                attn_scores[f"layer_{layer_id}"] = mean_score.item()
    return hook

# **æ³¨å†Œ Hook**
hooks = []
for layer_id, layer in enumerate(model.model.layers):
    hook = layer.self_attn.register_forward_hook(get_attention_scores_hook(layer_id))
    hooks.append(hook)

# **æµ‹è¯•è¾“å…¥**
text = "The quick brown fox jumps over the lazy dog."
inputs = tokenizer(text, return_tensors="pt").to("cuda")

# **æ‰§è¡Œ Forward Pass**
with torch.no_grad():
    model(**inputs, output_attentions=True)  # ğŸ”¹ å…³é”®ä¿®æ­£ï¼šç¡®ä¿è¿”å› attn_probs

# **ç§»é™¤ Hook**
for hook in hooks:
    hook.remove()

# **æ’åºå¹¶è¾“å‡º**
sorted_attn = sorted(attn_scores.items(), key=lambda x: -x[1])
print("Top 10 Most Important Layers by Attention Score:")
for layer, score in sorted_attn[:]:
    print(f"{layer}: {score}")

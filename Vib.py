import torch
import numpy as np
from transformers import AutoModelForCausalLM

# ğŸ› ï¸ è®¾ç½®ç¼“å­˜ç›®å½•
cache_dir = "/root/autodl-tmp/llm_weights"

# ğŸš€ åŠ è½½ LLaMA-7Bï¼ˆè‡ªåŠ¨åˆ†é… GPUï¼‰
model = AutoModelForCausalLM.from_pretrained(
    "pinkmanlove/llama-7b-hf",
    cache_dir=cache_dir,
    device_map="auto",
    torch_dtype=torch.float16  # âœ… ç”¨ float16 é™ä½æ˜¾å­˜å ç”¨
)

# ğŸ¯ è®¡ç®— SVDï¼ˆå®Œæ•´å¥‡å¼‚å€¼è°±ï¼‰
def singular_value_spectrum(weight_matrix):
    """è®¡ç®—å®Œæ•´ SVD å¥‡å¼‚å€¼è°±"""
    weight_matrix = weight_matrix.float()
    with torch.no_grad():
        U, S, V = torch.linalg.svd(weight_matrix, full_matrices=False)
    return S.cpu().numpy()  # è¿”å› SVD å¥‡å¼‚å€¼

# ğŸ¯ è®¡ç®—è°±ç†µï¼ˆSpectral Entropyï¼‰
def spectral_entropy(singular_values):
    """è®¡ç®—è°±ç†µ"""
    normalized_sv = singular_values / singular_values.sum()
    return -np.sum(normalized_sv * np.log(normalized_sv + 1e-9))

# ğŸ¯ è®¡ç®— ESDï¼ˆå®Œæ•´ç‰¹å¾å€¼è°±ï¼‰
def esd_spectrum(weight_matrix):
    """è®¡ç®—å®Œæ•´ ESDï¼ˆç‰¹å¾å€¼è°±åˆ†å¸ƒï¼‰"""
    weight_matrix = weight_matrix.float()
    with torch.no_grad():
        eigvals = torch.linalg.eigvalsh(weight_matrix @ weight_matrix.T)
    return eigvals.cpu().numpy()  # è¿”å›å®Œæ•´ç‰¹å¾å€¼

# ğŸ¯ è®¡ç®—å•å±‚é‡è¦æ€§
def process_layer(layer_idx, layer):
    print(f"Processing Layer {layer_idx}...")

    # ğŸ§  Attention å±‚ï¼ˆSVD + è°±ç†µï¼‰
    q_proj = layer.self_attn.q_proj.weight
    k_proj = layer.self_attn.k_proj.weight
    v_proj = layer.self_attn.v_proj.weight
    attn_svd_entropy = np.mean([
        spectral_entropy(singular_value_spectrum(q_proj)),
        spectral_entropy(singular_value_spectrum(k_proj)),
        spectral_entropy(singular_value_spectrum(v_proj))
    ])  # âœ… SVD + è°±ç†µ è®¡ç®—ä¿¡æ¯ä¼ æ’­èƒ½åŠ›

    # ğŸ”¥ MLP å±‚ï¼ˆå½’ä¸€åŒ– ESDï¼‰
    gate_proj = layer.mlp.gate_proj.weight
    up_proj = layer.mlp.up_proj.weight
    down_proj = layer.mlp.down_proj.weight
    mlp_esd = np.mean([
        np.max(esd_spectrum(gate_proj)),
        np.max(esd_spectrum(up_proj)),
        np.max(esd_spectrum(down_proj))
    ])  # âœ… å–æœ€å¤§ç‰¹å¾å€¼

    # ğŸ¯ Output å±‚ï¼ˆSVD + è°±ç†µï¼‰
    output_proj = layer.self_attn.o_proj.weight
    output_svd_entropy = spectral_entropy(singular_value_spectrum(output_proj))  # âœ… SVD + è°±ç†µ è®¡ç®—

    # ğŸ“Š è®¡ç®—ç›¸å¯¹é‡è¦æ€§
    layer_relative_importance = attn_svd_entropy * 0.5 - (mlp_esd * 0.5) + output_svd_entropy * 0.1

    

    # ğŸš€ é‡Šæ”¾æ˜¾å­˜
    del q_proj, k_proj, v_proj, gate_proj, up_proj, down_proj, output_proj
    torch.cuda.empty_cache()

    return layer_idx, layer_relative_importance

# ğŸš€ è®¡ç®—æ‰€æœ‰å±‚çš„é‡è¦æ€§
layer_importance_scores = []
for idx, layer in enumerate(model.model.layers):
    layer_importance_scores.append(process_layer(idx, layer))

# ğŸš€ å½’ä¸€åŒ–ï¼ˆ0.8 ~ 1.2 èŒƒå›´ï¼‰
scores = torch.tensor([imp[1] for imp in layer_importance_scores])
s1, s2 = 0.8, 1.2
max_score, min_score = scores.max(), scores.min()
normalized_scores = ((scores - min_score) / (max_score - min_score)) * (s2 - s1) + s1

# ğŸš€ æ’åº
sorted_layers = sorted(zip([imp[0] for imp in layer_importance_scores], normalized_scores.tolist()), key=lambda x: x[1], reverse=True)

print("\nğŸ” LLaMA 7B æ¯å±‚çš„å½’ä¸€åŒ–ç›¸å¯¹é‡è¦æ€§æ’åº:")
for idx, importance in sorted_layers:
    print(f"Layer {idx}: {importance:.4f}")

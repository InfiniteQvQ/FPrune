import torch
from transformers import AutoModelForCausalLM, LlamaTokenizer

# **åŠ è½½ LLaMA 7B æ¨¡å‹**
cache_dir = "/root/autodl-tmp/llm_weights"
model = AutoModelForCausalLM.from_pretrained(
    "pinkmanlove/llama-7b-hf",
    cache_dir=cache_dir,
    device_map="auto",  # è®© Hugging Face è‡ªåŠ¨åˆ†é…å¤šä¸ª GPU
    torch_dtype=torch.float16
)

tokenizer_name = "HuggingFaceM4/llama-7b-tokenizer"
tokenizer = LlamaTokenizer.from_pretrained(tokenizer_name)

# **æµ‹è¯•è¾“å…¥**
sample_text = "The quick brown fox jumps over the lazy dog."
inputs = tokenizer(sample_text, return_tensors="pt")

# âœ… **ä¿®æ­£å…³é”®ä»£ç **
device = model.device  # è·å–æ¨¡å‹æ‰€åœ¨è®¾å¤‡
inputs = {k: v.to(device) for k, v in inputs.items()}  # æŠŠè¾“å…¥æ•°æ®è½¬åˆ° `model.device`

# **å‰å‘ä¼ æ’­ï¼Œè·å–åŸºå‡†è¾“å‡º**
with torch.no_grad():
    base_output = model(**inputs).logits  # ç°åœ¨ä¸ä¼šæŠ¥é”™äº†

print("Model inference completed successfully!")

# **å®šä¹‰æ‰°åŠ¨å¹…åº¦**
delta = 1e-3

# **å­˜å‚¨å½±å“åˆ†æ•°**
influence_scores = []

# **è®¡ç®—æ¯ä¸€å±‚çš„å½±å“åˆ†æ•°**
for layer_idx, layer in enumerate(model.model.layers):
    print(f"Processing Layer {layer_idx}...")

    # éœ€è¦è®¡ç®—çš„æƒé‡
    components = {
        "Q": layer.self_attn.q_proj,
        "K": layer.self_attn.k_proj,
        "V": layer.self_attn.v_proj,
        "Output": layer.self_attn.o_proj,
        "Gate": layer.mlp.gate_proj,
        "Up": layer.mlp.up_proj,
        "Down": layer.mlp.down_proj,
    }

    for name, param in components.items():
        original_weight = param.weight.data.clone()

        # **æ‰°åŠ¨æƒé‡**
        param.weight.data.copy_(original_weight + delta)

        # **å‰å‘ä¼ æ’­**
        with torch.no_grad():
            perturbed_output = model(**inputs).logits

        # **è®¡ç®—å½±å“åˆ†æ•°**
        influence_score = torch.norm(base_output - perturbed_output).item() / delta
        influence_scores.append(influence_score)

        # **æ¢å¤åŸå§‹æƒé‡**
        param.weight.data.copy_(original_weight)

# **è½¬æ¢ä¸º 1D Tensor**
influence_tensor = torch.tensor(influence_scores, dtype=torch.float32, device=device)

# **æ‰“å°å½±å“åˆ†æ•°**
print("\nğŸ”¥ Influence Scores for Each Component ğŸ”¥")
print(influence_tensor)



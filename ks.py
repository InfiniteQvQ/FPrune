import torch
import weightwatcher as ww
from transformers import AutoModelForCausalLM

def analyze_layer_weightwatcher(layer, layer_idx):
    """ä½¿ç”¨ weightwatcher è®¡ç®— KS ç»Ÿè®¡é‡"""
    watcher = ww.WeightWatcher()
    details = watcher.analyze(layer, min_evals=3, randomize=False)  # è‡ªåŠ¨åˆ†ææƒé‡
    
    # æ‰“å°æ‰€æœ‰å¯ç”¨åˆ—ï¼Œç¡®ä¿ log_norm å­˜åœ¨
    print(f"Layer {layer_idx} Details:\n", details.columns)
    
    # è®¡ç®— KS ç»Ÿè®¡é‡ï¼ˆå½’ä¸€åŒ–å¤„ç†ï¼‰
    if "log_norm" in details.columns:
        ks_stat = details["log_norm"].mean()
        ks_stat = ks_stat / details["log_norm"].max()  # å½’ä¸€åŒ–
    else:
        ks_stat = float('nan')

    print(f"Layer {layer_idx}: KS D={ks_stat:.4f}")
    return float(ks_stat)  # åªè¿”å› KS ç»Ÿè®¡é‡

def analyze_llama7b(model_name="meta-llama/Llama-7b-hf", device="cuda"):
    """è®¡ç®— LLaMA-7B æ¯å±‚çš„ KS ç»Ÿè®¡é‡ï¼ˆç”¨ weightwatcherï¼‰"""
    
    cache_dir = "/root/autodl-tmp/llm_weights"
    model = AutoModelForCausalLM.from_pretrained(
        "pinkmanlove/llama-7b-hf",
        cache_dir=cache_dir,
        torch_dtype=torch.float16,
        device_map="auto"
    )
    
    ks_stats = []  # ä»…å­˜å‚¨ KS ç»Ÿè®¡é‡çš„åˆ—è¡¨

    for layer_idx, layer in enumerate(model.model.layers):  # éå† LLaMA Transformer å±‚
        ks_stat = analyze_layer_weightwatcher(layer, layer_idx)
        ks_stats.append(ks_stat)

    return ks_stats  # ä»…è¿”å› KS ç»Ÿè®¡é‡çš„åˆ—è¡¨

if __name__ == "__main__":
    ks_stats = analyze_llama7b(device="cuda")  # ä½¿ç”¨ GPU è®¡ç®—

    # æ‰“å°æœ€ç»ˆ KS ç»Ÿè®¡é‡åˆ—è¡¨
    print("\nğŸ”¥ Final KS Statistics (All Layers):")
    print(ks_stats)
